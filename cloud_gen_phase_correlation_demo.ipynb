{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from plotly.subplots import make_subplots\n",
    "from os import getcwd\n",
    "from math import ceil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a257ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_filter(x_freq, y_freq, factor=2.4):\n",
    "    eps = 10 ** -8\n",
    "    x, y = np.meshgrid(x_freq, y_freq)\n",
    "    f = np.hypot(x, y)\n",
    "    f = f ** factor + eps\n",
    "    return normalize(1 / f)\n",
    "\n",
    "\n",
    "def freq_sharp_round_filter(x_freq, y_freq, radius, reverse=False):\n",
    "    eps = 10 ** -8\n",
    "    x, y = np.meshgrid(x_freq, y_freq)\n",
    "    if reverse:\n",
    "        f = np.zeros((x_size, y_size))\n",
    "    else:\n",
    "        f = np.ones((x_size, y_size))\n",
    "    \n",
    "    for i, xx in enumerate(x_freq):\n",
    "        for j, yy in enumerate(y_freq):\n",
    "            if xx ** 2 + yy ** 2 <= radius ** 2:\n",
    "                if reverse:\n",
    "                    f[i, j] = 1\n",
    "                else:\n",
    "                    f[i, j] = 0\n",
    "    return normalize(f)\n",
    "\n",
    "\n",
    "def freq_sharp_square_filter(x_freq, y_freq, width, reverse=False):\n",
    "    eps = 10 ** -8\n",
    "    x, y = np.meshgrid(x_freq, y_freq)\n",
    "    if reverse:\n",
    "        f = np.zeros((x_size, y_size))\n",
    "    else:\n",
    "        f = np.ones((x_size, y_size))\n",
    "    \n",
    "    for i, xx in enumerate(x_freq):\n",
    "        for j, yy in enumerate(y_freq):\n",
    "            if abs(xx) + abs(yy) <= width:\n",
    "                if reverse:\n",
    "                    f[i, j] = 1\n",
    "                else:\n",
    "                    f[i, j] = 0\n",
    "    return normalize(f)\n",
    "\n",
    "\n",
    "def spatial_smooth_filter(x_size, y_size, depth, horiz=True):\n",
    "    values = np.linspace(0, 1, depth)\n",
    "    values = 6 * values ** 5 - 15 * values ** 4 + 10 * values ** 3\n",
    "    values = 1 - values\n",
    "    if horiz:\n",
    "        kernel = np.tile(values, (y_size, 1))\n",
    "    else:\n",
    "        kernel = values[:, np.newaxis] * np.ones((1, x_size))   \n",
    "    return kernel\n",
    "\n",
    "\n",
    "def find_ft(img):\n",
    "    ft = np.fft.fft2(img)\n",
    "    return np.fft.fftshift(ft)\n",
    "\n",
    "\n",
    "def find_ift(ft):\n",
    "    ift = np.fft.ifftshift(ft)\n",
    "    return np.fft.ifft2(ift)\n",
    "\n",
    "\n",
    "def normalize(arr):\n",
    "    min_val = abs(np.min(arr))\n",
    "    max_val = abs(np.max(arr))\n",
    "    return (arr + min_val) / (min_val + max_val)\n",
    "\n",
    "\n",
    "def normalize_img(img):\n",
    "    img_min = abs(np.min(img))\n",
    "    img_max = abs(np.max(img))\n",
    "    img_norm = 255 * (img + img_min) / (img_min + img_max)\n",
    "    return img_norm.astype(int)\n",
    "\n",
    "\n",
    "def gen_cloud(x_size, y_size, factor=2.4):\n",
    "    xx = np.linspace(-x_size / 2, x_size / 2, x_size)\n",
    "    yy = np.linspace(-y_size / 2, y_size / 2, y_size)\n",
    "    whitenoise = np.random.normal(0, 1, (y_size, x_size))\n",
    "    cloud_freq = find_ft(whitenoise)\n",
    "    kernel = freq_filter(xx, yy, factor=factor)\n",
    "    cloud_freq_filtered = cloud_freq * kernel\n",
    "    cloud_spatial = find_ift(cloud_freq_filtered).real\n",
    "    return normalize_img(cloud_spatial)\n",
    "\n",
    "\n",
    "def show_images(*images, vmin=0, vmax=255, x_fig_size=10, cmap='gray', y_fig_size=10, graphs_per_row=2):\n",
    "    if len(images) == 1:\n",
    "        plt.imshow(images[0], cmap='gray', vmin=0, vmax=255)\n",
    "    else:\n",
    "        row_num = ceil(len(images) / graphs_per_row)\n",
    "        col_num = ceil(len(images) / row_num)\n",
    "    \n",
    "        f, axes = plt.subplots(row_num, col_num, sharey=True, figsize=(x_fig_size, y_fig_size))\n",
    "\n",
    "        for ax, img in zip(axes.flatten(), images):\n",
    "            ax.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "        \n",
    "        \n",
    "def make_img_transition_x(img, depth, is_dx_pos=True):\n",
    "    y_size, x_size = img.shape\n",
    "    additional_img = gen_cloud(x_size + depth, y_size)   \n",
    "    transition_kernel = spatial_smooth_filter(x_size, y_size, depth)     \n",
    "    \n",
    "    new_img = np.copy(img)\n",
    "    if is_dx_pos:\n",
    "        new_img[:, -depth:x_size] = img[:, -depth:x_size] * transition_kernel + \\\n",
    "                                additional_img[:, 0:depth] * (1 - transition_kernel)\n",
    "        return new_img, additional_img[:, depth:]    \n",
    "    else:\n",
    "        transition_kernel = np.fliplr(transition_kernel)\n",
    "        new_img[:, 0:depth] = img[:, 0:depth] * transition_kernel + \\\n",
    "                          additional_img[:, -depth:] * (1 - transition_kernel)  \n",
    "        return new_img, additional_img[:, 0:-depth]    \n",
    "\n",
    "\n",
    "def make_img_transition_y(img, depth, is_dy_pos=True):\n",
    "    y_size, x_size = img.shape\n",
    "    additional_img = gen_cloud(x_size, y_size + depth)   \n",
    "    transition_kernel = spatial_smooth_filter(x_size, y_size, depth, horiz=False)\n",
    "        \n",
    "    new_img = np.copy(img)\n",
    "    if is_dy_pos:\n",
    "        new_img[-depth:x_size, :] = img[-depth:x_size, :] * transition_kernel + \\\n",
    "                                additional_img[0:depth, :] * (1 - transition_kernel)\n",
    "        return new_img, additional_img[depth:, :]    \n",
    "    else:\n",
    "        transition_kernel = np.flipud(transition_kernel)\n",
    "        new_img[0:depth, :] = img[0:depth, :] * transition_kernel + \\\n",
    "                          additional_img[-depth:, :] * (1 - transition_kernel)  \n",
    "        return new_img, additional_img[0:-depth:1, :]    \n",
    "    \n",
    "\n",
    "def make_img_transition_xy(img, img_depth, is_dx_pos=True, is_dy_pos=True):\n",
    "    new_img, add_img = make_img_transition_x(img, depth, is_dx_pos=is_dx_pos)\n",
    "    new_img = np.concatenate((new_img, add_img), axis=1)\n",
    "    \n",
    "    new_img, add_img = make_img_transition_y(new_img, depth, is_dy_pos=is_dy_pos)\n",
    "    new_img = np.concatenate((new_img, add_img), axis=0)\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "\n",
    "def shift_img_x(img, width, dx, is_dx_pos=True): \n",
    "    # Wind blows in negative X dirrection\n",
    "    if is_dx_pos:\n",
    "        return img[:, dx:width + dx]\n",
    "    else:\n",
    "        return img[:, width - dx:-dx]\n",
    "\n",
    "\n",
    "def shift_img_y(img, height, dy, is_dy_pos=True):\n",
    "    # Wind blows in negative Y dirrection\n",
    "    if is_dy_pos:\n",
    "        return img[dy:height + dy, :]\n",
    "    else:\n",
    "        return img[height - dy:-dy, :]\n",
    "\n",
    "    \n",
    "def shift_img_xy(img, window_shape, dx, dy, is_dx_pos=True, is_dy_pos=True):\n",
    "    height, width = window_shape\n",
    "    \n",
    "    shifted_img = shift_img_x(new_img, width, dx, is_dx_pos=is_dx_pos)\n",
    "    shifted_img = shift_img_y(shifted_img, height, dy, is_dy_pos=is_dy_pos)\n",
    "    \n",
    "    return shifted_img\n",
    "\n",
    "\n",
    "CURRENT_DIR = getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5936de",
   "metadata": {},
   "source": [
    "# Rubik's cube example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = Image.open(CURRENT_DIR + '/img/cube_1.png').convert('L')\n",
    "cube_fr = find_ft(cube)\n",
    "\n",
    "x_size, y_size = cube_fr.shape\n",
    "xx = np.linspace(-x_size / 2, x_size / 2, x_size)\n",
    "yy = np.linspace(-y_size / 2, y_size / 2, y_size)\n",
    "\n",
    "kernel = normalize(freq_sharp_round_filter(yy, xx, radius=50))\n",
    "eps = 10 ** -10\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 10))\n",
    "ax1.imshow(cube, cmap='gray', vmin=0, vmax=255)\n",
    "# Wrong scaling, but it gives a really interesting visual representation\n",
    "ax2.imshow(find_ift(cube_fr * kernel).real, cmap='gray', vmin=0, vmax=np.max(np.log(np.absolute(cube_fr + eps))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0313ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = Image.open(CURRENT_DIR + '/img/woman.jpeg').convert('L')\n",
    "cube_fr = find_ft(cube)\n",
    "\n",
    "x_size, y_size = cube_fr.shape\n",
    "xx = np.linspace(-x_size / 2, x_size / 2, x_size)\n",
    "yy = np.linspace(-y_size / 2, y_size / 2, y_size)\n",
    "\n",
    "fps = 30\n",
    "seconds_num = 5\n",
    "x_mesh, y_mesh = np.meshgrid(xx, yy)\n",
    "\n",
    "radius = 300\n",
    "cube_freq = [cube]\n",
    "kernel_arr = []\n",
    "\n",
    "for i in range(fps * seconds_num):\n",
    "    kernel = normalize(freq_sharp_round_filter(xx, yy, radius=i / fps / seconds_num * 150))\n",
    "    kernel_arr.append(kernel)\n",
    "    cube_freq.append(normalize_img(find_ift(cube_fr * kernel).real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49712d72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "im = plt.imshow(cube_freq[0], interpolation='none', aspect='equal', cmap='gray')\n",
    "\n",
    "\n",
    "def animate_func(i): \n",
    "    im.set_array(cube_freq[i])\n",
    "    return [im]\n",
    "\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "    fig, \n",
    "    animate_func, \n",
    "    frames = seconds_num * fps,\n",
    "    interval = 1000 / fps, # in ms\n",
    ")\n",
    "\n",
    "\n",
    "# anim.save('women.gif', writer='pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195cd75e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "cube = Image.open(CURRENT_DIR + '/img/cube_1.png').convert('L')\n",
    "cube_fr = find_ft(cube)\n",
    "\n",
    "eps = 10 ** -10\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 10))\n",
    "ax1.imshow(cube, cmap='gray', vmin=0, vmax=255)\n",
    "ax2.imshow(np.log(np.absolute(cube_fr + eps)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2b96d",
   "metadata": {},
   "source": [
    "# Phase correlation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = Image.open(CURRENT_DIR + '/img/horse_1.png').convert('L')\n",
    "f2 = Image.open(CURRENT_DIR + '/img/horse_translated_1.png').convert('L')\n",
    "\n",
    "f1_freq = find_ft(f1)\n",
    "f2_freq = find_ft(f2)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 15))\n",
    "ax1.imshow(f1, cmap='gray', vmin=0, vmax=255)\n",
    "ax2.imshow(f2, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dff467",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 15))\n",
    "ax1.imshow(np.log(np.absolute(f1_freq)), cmap='gray')\n",
    "ax2.imshow(np.log(np.absolute(f2_freq)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57411985",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 15))\n",
    "ax1.imshow(np.angle(f1_freq, deg=True), cmap='gray')\n",
    "ax2.imshow(np.angle(f2_freq, deg=True), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncps = f1_freq * np.conj(f2_freq) / np.abs(f1_freq * f2_freq)\n",
    "shift = find_ift(ncps)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 15))\n",
    "ax1.imshow(np.absolute(ncps), cmap='gray')\n",
    "ax2.imshow(np.absolute(shift), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc90e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.unravel_index(np.argmax(shift, axis=None), shift.shape)\n",
    "[i - j for i, j in zip(shift.shape, ind)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f1dfa",
   "metadata": {},
   "source": [
    "# Shifting Pink Noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 256\n",
    "y_size = 256\n",
    "\n",
    "xx = np.linspace(-x_size / 2, x_size / 2, x_size)\n",
    "yy = np.linspace(-y_size / 2, y_size / 2, y_size)\n",
    "\n",
    "# Generating cloud image\n",
    "whitenoise = np.random.normal(0, 1, (y_size, x_size))\n",
    "ft_arr = find_ft(whitenoise)\n",
    "kernel = freq_filter(xx, yy, factor=2.4)\n",
    "\n",
    "pink_ft_arr = ft_arr * kernel\n",
    "pink_noise = normalize_img(find_ift(pink_ft_arr).real)\n",
    "\n",
    "# Shifting initial image\n",
    "dx = 25\n",
    "dy = 20\n",
    "\n",
    "x_mesh, y_mesh = np.meshgrid(xx, yy)\n",
    "shift = np.exp(-1j * 2 * np.pi  * (x_mesh * dx / y_size + y_mesh * dy / x_size));\n",
    "\n",
    "# Apply the phase shift along both axes\n",
    "f_freq_shifted = pink_ft_arr * shift\n",
    "shifted_pink_noise = normalize_img(find_ift(f_freq_shifted).real)\n",
    "\n",
    "show_images(pink_noise, shifted_pink_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b688b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Generating cloud image\n",
    "whitenoise = np.random.normal(0, 1, (y_size, x_size))\n",
    "ft_arr = find_ft(whitenoise)\n",
    "kernel = freq_filter(xx, yy, factor=2)\n",
    "\n",
    "pink_ft_arr = ft_arr * kernel\n",
    "pink_noise = find_ift(pink_ft_arr).real\n",
    "\n",
    "# Shift values\n",
    "dx = 200\n",
    "dy = 0\n",
    "\n",
    "# Shift values per one frame\n",
    "fps = 30\n",
    "seconds_num = 5\n",
    "dxx = dx / fps / seconds_num\n",
    "dyy = dy / fps / seconds_num\n",
    "\n",
    "x_mesh, y_mesh = np.meshgrid(xx, yy)\n",
    "shift = np.exp(-1j * 2 * np.pi  * (x_mesh * dxx / y_size + y_mesh * dyy / x_size));\n",
    "\n",
    "snapshots_freq = [pink_ft_arr]\n",
    "snapshots_spatial = [pink_noise]\n",
    "for _ in range(fps * seconds_num):\n",
    "    # print(np.sum(np.absolute(snapshots_freq[-1]) ** 2))\n",
    "    snapshots_freq.append(snapshots_freq[-1] * shift)\n",
    "    snapshots_spatial.append(find_ift(snapshots_freq[-1]).real)\n",
    "\n",
    "    \n",
    "fig = plt.figure(figsize=(8,8))\n",
    "frame = snapshots_spatial[0]\n",
    "im = plt.imshow(frame, interpolation='none', aspect='auto', cmap='gray')\n",
    "\n",
    "\n",
    "def animate_func(i):\n",
    "    im.set_array(snapshots_spatial[i])\n",
    "    plt.title(f\"X shift {i * dxx:.2f} \\n Y shift {i * dyy:.2f}\")\n",
    "    return [im]\n",
    "\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "    fig, \n",
    "    animate_func, \n",
    "    frames = seconds_num * fps,\n",
    "    interval = 1000 / fps, # in ms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f48103",
   "metadata": {},
   "source": [
    "# Smooth transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee403b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x_size = 256\n",
    "y_size = 256\n",
    "\n",
    "xx = np.linspace(-x_size / 2, x_size / 2, x_size)\n",
    "yy = np.linspace(-y_size / 2, y_size / 2, y_size)  \n",
    "depth = int(x_size * 0.3)\n",
    "\n",
    "img_1 = gen_cloud(x_size, y_size)\n",
    "img_2 = gen_cloud(x_size, y_size)\n",
    "\n",
    "img_1_cut = img_1[:, -depth:x_size]\n",
    "img_2_cut = img_2[:, 0:depth]\n",
    "img_2_tr = img_2[:,depth:x_size]\n",
    "\n",
    "x_kernel = spatial_smooth_filter(x_size, y_size, depth)\n",
    "img1_cut_pr = img_1_cut * x_kernel + img_2_cut * (1 - x_kernel)\n",
    "img_1[:,-depth:x_size] = img1_cut_pr\n",
    "img_concat = np.concatenate((img_1, img_2_tr), axis=1)\n",
    "\n",
    "show_images(img_1, img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6d4b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(depth), x_kernel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2686fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(img_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f202f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_cloud(x_size, y_size)\n",
    "img_new, add_img = make_img_transition_x(img, depth)\n",
    "img_concat = np.concatenate((img_new, add_img), axis=1)\n",
    "\n",
    "show_images(img, img_new, add_img, img_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e801d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_cloud(x_size, y_size)\n",
    "img_new, add_img = make_img_transition_x(img, depth, is_dx_pos=False)\n",
    "img_concat = np.concatenate((add_img, img_new), axis=1)\n",
    "\n",
    "show_images(img, img_new, add_img, img_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c42fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_cloud(x_size, y_size)\n",
    "img_new, add_img = make_img_transition_y(img, depth)\n",
    "img_concat = np.concatenate((img_new, add_img), axis=0)\n",
    "\n",
    "show_images(img, img_new, add_img, img_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f100b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_cloud(x_size, y_size)\n",
    "img_new, add_img = make_img_transition_y(img, depth, is_dy_pos=False)\n",
    "img_concat = np.concatenate((add_img, img_new), axis=0)\n",
    "\n",
    "show_images(img, img_new, add_img, img_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfe7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_cloud(x_size, y_size)\n",
    "\n",
    "img_new, img_x = make_img_transition_x(img, depth)\n",
    "img_row_1 = np.concatenate((img_new, img_x), axis=1)\n",
    "\n",
    "img_new, img_y = make_img_transition_y(img_row_1, depth)\n",
    "img_row_2 = np.concatenate((img_new, img_y), axis=0)\n",
    "\n",
    "show_images(img_row_1, img_row_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ebc5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_cloud(x_size, y_size)\n",
    "\n",
    "img_new, img_x = make_img_transition_x(img, depth, is_dx_pos=False)\n",
    "img_row_1 = np.concatenate((img_x, img_new), axis=1)\n",
    "\n",
    "img_new, img_y = make_img_transition_y(img_row_1, depth)\n",
    "img_row_2 = np.concatenate((img_new, img_y), axis=0)\n",
    "\n",
    "show_images(img_row_1, img_row_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8be9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_cloud(x_size, y_size)\n",
    "\n",
    "img_new, img_x = make_img_transition_x(img, depth)\n",
    "img_row_1 = np.concatenate((img_new, img_x), axis=1)\n",
    "\n",
    "img_new, img_y = make_img_transition_y(img_row_1, depth, is_dy_pos=False)\n",
    "img_row_2 = np.concatenate((img_y, img_new), axis=0)\n",
    "\n",
    "show_images(img_row_1, img_row_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e42545",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_cloud(x_size, y_size)\n",
    "\n",
    "img_new, img_x = make_img_transition_x(img, depth, is_dx_pos=False)\n",
    "img_row_1 = np.concatenate((img_x, img_new), axis=1)\n",
    "\n",
    "img_new, img_y = make_img_transition_y(img_row_1, depth, is_dy_pos=False)\n",
    "img_row_2 = np.concatenate((img_y, img_new), axis=0)\n",
    "\n",
    "show_images(img_row_1, img_row_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7083d8c",
   "metadata": {},
   "source": [
    "# Example of XY smooth transition and shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28776bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x_size = 256\n",
    "y_size = 256\n",
    "depth = int(x_size * 0.3)\n",
    "\n",
    "img = gen_cloud(x_size, y_size)\n",
    "\n",
    "new_img = make_img_transition_xy(img, depth)\n",
    "shifted_img = shift_img_xy(new_img, img.shape, 75, 50)\n",
    "\n",
    "show_images(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(shifted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ddd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Shift values\n",
    "dx = 200\n",
    "dy = 200\n",
    "\n",
    "# Shift values per one frame\n",
    "fps = 30\n",
    "seconds_num = 5\n",
    "dxx = dx / fps / seconds_num\n",
    "dyy = dy / fps / seconds_num\n",
    "\n",
    "dx_arr = [0]\n",
    "dy_arr = [0]\n",
    "for i in range(fps * seconds_num):\n",
    "    dx_arr.append(dx_arr[-1] + dxx)\n",
    "    dy_arr.append(dy_arr[-1] + dyy)\n",
    "    \n",
    "\n",
    "for i in range(fps * seconds_num):\n",
    "    dx_arr[i] = round(dx_arr[i])\n",
    "    dy_arr[i] = round(dy_arr[i])\n",
    "    \n",
    "\n",
    "x_mesh, y_mesh = np.meshgrid(xx, yy)\n",
    "snapshots = []\n",
    "for i in range(fps * seconds_num):\n",
    "    snapshots.append(shift_img_xy(new_img, (256, 256), dx_arr[i], dy_arr[i]))\n",
    "\n",
    "    \n",
    "fig = plt.figure(figsize=(5,5))\n",
    "frame = snapshots[0]\n",
    "im = plt.imshow(frame, interpolation='none', aspect='auto', cmap='gray')\n",
    "\n",
    "\n",
    "def animate_func(i):\n",
    "    im.set_array(snapshots[i])\n",
    "    plt.title(f\"X shift {i * dxx:.2f} \\n Y shift {i * dyy:.2f}\")\n",
    "    return [im]\n",
    "\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "    fig, \n",
    "    animate_func, \n",
    "    frames = seconds_num * fps,\n",
    "    interval = 1000 / fps, # in ms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d04840",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(new_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebc6fc",
   "metadata": {},
   "source": [
    "# 2D distribution test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac7a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# True parameters of the 2D exponential distribution\n",
    "true_lambda1 = 0.5\n",
    "true_lambda2 = 0.8\n",
    "\n",
    "# Number of data points\n",
    "n = 100\n",
    "\n",
    "# Generate random data from the 2D exponential distribution\n",
    "np.random.seed(42)\n",
    "x = np.random.exponential(scale=1/true_lambda1, size=n)\n",
    "y = np.random.exponential(scale=1/true_lambda2, size=n)\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def neg_log_likelihood(params):\n",
    "    lambda1, lambda2 = params\n",
    "    return -np.sum(np.log(lambda1 * lambda2 * np.exp(-lambda1 * x - lambda2 * y)))\n",
    "\n",
    "# Initial parameter guesses for optimization\n",
    "initial_params = [0.1, 0.1]\n",
    "\n",
    "# Maximize the negative log-likelihood to estimate parameters\n",
    "result = minimize(neg_log_likelihood, initial_params, method='L-BFGS-B')\n",
    "\n",
    "# Extract estimated parameters\n",
    "estimated_lambda1, estimated_lambda2 = result.x\n",
    "\n",
    "# Print true and estimated parameters\n",
    "print(\"True Lambda 1:\", true_lambda1)\n",
    "print(\"Estimated Lambda 1:\", estimated_lambda1)\n",
    "print(\"True Lambda 2:\", true_lambda2)\n",
    "print(\"Estimated Lambda 2:\", estimated_lambda2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf9918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters for the bivariate exponential distribution\n",
    "lambda1 = 0.5\n",
    "lambda2 = 0.7\n",
    "\n",
    "# Generate synthetic data from the bivariate exponential distribution\n",
    "num_samples = 100\n",
    "x_samples = np.random.exponential(scale=1/lambda1, size=num_samples)\n",
    "y_samples = np.random.exponential(scale=1/lambda2, size=num_samples)\n",
    "\n",
    "# Create a scatter plot of the generated data\n",
    "plt.scatter(x_samples, y_samples, color='blue', alpha=0.5)\n",
    "plt.title('2D Exponential Distribution')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_cloud(100, 100)\n",
    "img_freq = find_ft(img)\n",
    "magnitude = np.absolute(img_freq)\n",
    "\n",
    "plt.imshow(np.log(magnitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bc064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def bivariate_exponential_log_likelihood(params, x, y, z):\n",
    "    lambda1, lambda2 = params\n",
    "    n = len(x)\n",
    "    log_likelihood = n * np.log(lambda1 * lambda2) - lambda1 * np.sum(x) - lambda2 * np.sum(y)\n",
    "    return -log_likelihood\n",
    "\n",
    "# Convert the 2D z array into separate x, y, and z values\n",
    "x_indices, y_indices = np.indices(magnitude.shape)\n",
    "x = x_indices.flatten()\n",
    "y = y_indices.flatten()\n",
    "magnitude = magnitude.flatten()\n",
    "\n",
    "initial_guess = [0.5, 0.5]  # Initial parameter guesses\n",
    "result = minimize(bivariate_exponential_log_likelihood, initial_guess, args=(x, y, z), method='BFGS')\n",
    "estimated_params = result.x\n",
    "\n",
    "print(\"Estimated Parameters:\", estimated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([[0.1, 0.05, 0.2],\n",
    "              [0.02, 0.15, 0.1],\n",
    "              [0.05, 0.3, 0.25]])\n",
    "\n",
    "x_indices, y_indices = np.indices(z.shape)\n",
    "x = x_indices.flatten()\n",
    "y = y_indices.flatten()\n",
    "z = z.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
