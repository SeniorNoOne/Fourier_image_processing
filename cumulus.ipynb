{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from os import getcwd\n",
    "from common.utils import * \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "figsize = (10, 8.5)\n",
    "figsize_small = (5, 8.5)\n",
    "\n",
    "input_dir = getcwd() + '/img/input_samples/'\n",
    "output_dir = getcwd() + '/files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d496154c",
   "metadata": {},
   "source": [
    "### Cumulus test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f05274",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_img(input_dir + '2.jpg')\n",
    "img_fr = find_ft_2d(img)\n",
    "\n",
    "img_shape = img.shape\n",
    "y_size, x_size = img_shape\n",
    "x_shift, y_shift = x_size // 2, y_size // 2\n",
    "xx, yy = freq_numbers_2d(img_shape)\n",
    "x, y = freq_mesh_2d(img_shape)\n",
    "\n",
    "magn_raw = np.abs(img_fr)\n",
    "magn = normalize(magn_raw)\n",
    "magn_factor = normalize_psd(magn_raw, magn)\n",
    "phase = np.angle(img_fr)\n",
    "restored_img = find_ift_2d(magn_factor * magn * np.exp(1j * phase)).real\n",
    "\n",
    "f, ax = show_images(img, np.log10(magn), phase, restored_img, figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e184ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = show_surfaces(np.log10(magn), axes=(xx, yy))\n",
    "# f_1.update_layout(scene = dict(zaxis = dict(range=[-5, 0])))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_2 = show_surfaces(phase[x_size // 2 - 10: x_size // 2 + 10, y_size // 2 - 10: y_size // 2 + 10], axes=(list(range(20)), list(range(20))))\n",
    "f_2 = show_surfaces(phase, axes=(xx, yy))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa94a0",
   "metadata": {},
   "source": [
    "### Generating pseudo random phase trying to mimic same phase distribution along each axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6add8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_phase_x = np.zeros(img_shape)\n",
    "for i in range(x_size):\n",
    "    new_phase_x[:, i] = surrogates(phase[:, i], 1)\n",
    "\n",
    "new_phase_y = np.zeros(img_shape)\n",
    "for i in range(y_size):\n",
    "    new_phase_y[i, :] = surrogates(phase[i, :], 1)\n",
    "    \n",
    "# New phase and 1/f kernel\n",
    "new_phase_sur = new_phase_x + new_phase_y \n",
    "\n",
    "# Restoring image using original phase and generated phase\n",
    "restored_img = find_ift_2d(magn_factor * magn * np.exp(1j * new_phase_sur))\n",
    "\n",
    "f, ax = show_images(new_phase_sur, restored_img, figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3214f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring image using 1/f kernel for magnitude and new phase \n",
    "# Results are equal to regular FFT syntesis\n",
    "\n",
    "kernel = freq_pink_filter_2d(xx, yy)\n",
    "kernel_magn_factor = normalize_psd(magn_raw, kernel)\n",
    "restored_img = find_ift_2d(kernel_magn_factor * kernel * np.exp(1j * new_phase_sur))\n",
    "\n",
    "f, ax = show_images(np.log10(kernel), restored_img, figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7ab7c",
   "metadata": {},
   "source": [
    "### Restoring image using linearly changing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2053c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_phase = [np.pi / 3, 2 * np.pi / 3, np.pi, np.pi / 2, 3 * np.pi / 2]\n",
    "initial_phase += [-i for i in initial_phase]\n",
    "whitenoise = np.random.normal(0, 1, img_shape)\n",
    "whitenoise_fr = find_ft_2d(whitenoise)\n",
    "lin_random_phase = np.angle(whitenoise_fr)\n",
    "\n",
    "width = 5\n",
    "scale = 0.2\n",
    "alpha_x = 1.4\n",
    "alpha_y = 1.\n",
    "step = 1\n",
    "\n",
    "for i in range(-width, width + 1, step):\n",
    "    initial_phase_x = random.choice(initial_phase)\n",
    "    initial_phase_y = random.choice(initial_phase)\n",
    "    phase_y = lin_phase(initial_phase_y, initial_phase_y + random.choice(initial_phase), y_size)\n",
    "    phase_x = lin_phase(initial_phase_x, initial_phase_x + random.choice(initial_phase), x_size)\n",
    "    lin_random_phase[y_shift + i, :] = phase_x\n",
    "    lin_random_phase[:, x_shift + i] = phase_y\n",
    "    \n",
    "\n",
    "restored_img_fr = magn_factor * magn * np.exp(1j * lin_random_phase)\n",
    "restored_img = find_ift_2d(restored_img_fr)\n",
    "\n",
    "f, ax = show_images(lin_random_phase, restored_img, figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea4982",
   "metadata": {},
   "outputs": [],
   "source": [
    "magn_factor = normalize_psd(magn_raw, kernel)\n",
    "restored_img_fr = magn_factor * kernel * np.exp(1j * lin_random_phase)\n",
    "restored_img = find_ift_2d(restored_img_fr)\n",
    "\n",
    "f, ax = show_images(lin_random_phase, restored_img, figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a71127",
   "metadata": {},
   "source": [
    "### 1D regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b684ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximation along Y-axis\n",
    "\n",
    "alpha = 1.\n",
    "dy = 1\n",
    "factor_y = [1, 0.2, 0.2, 0.15, 0.25, 0.08]\n",
    "const_y = [0.0019, 0.0008, 0.0015, 0.001, 0.0012, 0.0008]\n",
    "\n",
    "y_vals = magn[x_size // 2 + dy, magn.shape[1] // 2:] \n",
    "x_vals = np.array(range(len(y_vals)))\n",
    "\n",
    "w_y = factor_y[abs(dy)] * ((1 + abs(x_vals)) ** (-alpha) + const_y[abs(dy)])\n",
    "# kernel = freq_pink_filter_2d(xx, yy, factor=1)\n",
    "# kernel[magn.shape[0] // 2, :] = w\n",
    "\n",
    "plt.plot(x_vals, w_y)\n",
    "plt.plot(x_vals[1:], y_vals[1:])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c579ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximation along X-axis\n",
    "\n",
    "alpha = 1.45\n",
    "dx = 1\n",
    "factor_x = [1, 1, 1, 1, 1, 1]\n",
    "const_x = [0.00015, 0.00015, 0.00015, 0.00015, 0.00015, 0.00015]\n",
    "\n",
    "y_vals = magn[magn.shape[0] // 2:, y_size // 2 + dx] \n",
    "x_vals = np.array(range(len(y_vals)))\n",
    "w_x = factor_x[abs(dx)] * ((1 + abs(x_vals)) ** (-alpha) + const_x[abs(dx)])\n",
    "\n",
    "plt.plot(x_vals, w_x)\n",
    "plt.plot(x_vals[0:], y_vals[0:])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76681da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximation along Y = X\n",
    "alpha1 = 1.8\n",
    "alpha2 = 1.0\n",
    "\n",
    "l = magn.shape[0] // 2\n",
    "y_vals = np.zeros(l)\n",
    "\n",
    "for i in range(l):\n",
    "    y_vals[i] = magn[l + i, l + i]\n",
    "x_vals = np.array(range(len(y_vals))) * 2 ** 0.5\n",
    "\n",
    "y_log = np.log10(y_vals)\n",
    "x_log = np.log10(1 + x_vals)\n",
    "\n",
    "w_diag = (1 + abs(x_vals)) ** (-alpha1) + 0.02 * (1 + abs(x_vals)) ** (-alpha2)\n",
    "# kernel[:, magn.shape[1] // 2] = w\n",
    "\n",
    "plt.plot(x_vals, w_diag)\n",
    "plt.plot(x_vals[1:], y_vals[1:])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06465fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined kernel with previous approximation results\n",
    "width = 5\n",
    "scale = 0.2\n",
    "alpha_x = 1.4\n",
    "alpha_y = 1.\n",
    "step = 1\n",
    "\n",
    "# kernel = freq_pink_filter_2d(xx, yy, factor=0.5)\n",
    "kernel = fit_clement(xx, yy, alpha1, alpha2)\n",
    "# kernel = np.zeros((x_size, y_size))\n",
    "\n",
    "for i in range(-width, width + 1, step):\n",
    "    w_y = factor_y[abs(i)] * ((1 + abs(yy)) ** (-alpha_y) + const_y[abs(i)])\n",
    "    w_x = factor_x[abs(i)] * ((1 + abs(xx)) ** (-alpha_x) + const_x[abs(i)])\n",
    "    kernel[y_shift + i, :] = w_x\n",
    "    kernel[:, x_shift + i] = w_y\n",
    "    \n",
    "# kernel[magn.shape[0] // 2, :] = w_y \n",
    "# kernel[:, magn.shape[1] // 2] = w_x \n",
    "kernel = normalize(kernel)\n",
    "\n",
    "f = show_surfaces(np.log10(kernel), axes=(xx, yy))\n",
    "# f.update_layout(scene=dict(zaxis = dict(range=[-5, 0])))\n",
    "# f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc218db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restring image using approximated kernel and original phase\n",
    "restored_img_1 = find_ift_2d(kernel * np.exp(1j * phase)).real\n",
    "a, b = lin_regression(restored_img_1, img)\n",
    "restored_img_1 = a * restored_img_1 + b\n",
    "\n",
    "# Restring image using approximated kernel and random phase\n",
    "whitenoise = np.random.normal(0, 1, (y_size, x_size))\n",
    "random_phase = np.angle(find_ft_2d(whitenoise))\n",
    "kernel_magn_factor = normalize_psd(magn_raw, kernel)\n",
    "restored_img_2 = find_ift_2d(kernel_magn_factor * kernel * np.exp(1j * random_phase)).real\n",
    "\n",
    "# Restring image using approximated kernel and linear phase\n",
    "restored_img_3 = find_ift_2d(kernel_magn_factor * kernel * np.exp(1j * lin_random_phase)).real\n",
    "\n",
    "# plt.imshow(restored_img_1, cmap='gray', vmin=np.min(img), vmax=np.max(img))\n",
    "f, ax = show_images(restored_img_1, restored_img_2, restored_img_3, figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2545dad",
   "metadata": {},
   "source": [
    "### 2D regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = magn\n",
    "x_vals = freq_filter_2d(xx, yy)\n",
    "\n",
    "y_log = np.log10(y_vals)\n",
    "x_log = np.log10(1 + x_vals)\n",
    "\n",
    "alpha = -2 * np.sum(y_log * x_log) / np.sum(x_log ** 2) \n",
    "kernel = freq_pink_filter_2d(xx, yy, factor=alpha / 2)\n",
    "print(f\"alpha = {alpha / 2}\")\n",
    "\n",
    "f = show_surfaces(np.log10(kernel), np.log10(magn), axes=(xx, yy))\n",
    "# f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring image using approximated kernel and original phase \n",
    "kernel_magn_factor = normalize_psd(magn_raw, kernel)\n",
    "restored_image_1 = find_ift_2d(kernel_magn_factor * kernel * np.exp(1j * phase)).real\n",
    "a, b = lin_regression(restored_image_1, img)\n",
    "restored_image_1 = a * restored_image_1 + b\n",
    "\n",
    "# Restoring image using approximated kernel and random phase \n",
    "restored_image_2 = find_ift_2d(kernel_magn_factor * kernel * np.exp(1j * random_phase)).real\n",
    "\n",
    "# Restoring image using approximated kernel and linear phase \n",
    "restored_image_3 = find_ift_2d(kernel_magn_factor * kernel * np.exp(1j * lin_random_phase)).real\n",
    "\n",
    "f, ax = show_images(restored_image_1, restored_image_2, restored_image_3, vrange=(np.min(img), np.max(img)), \n",
    "                    figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4698d8cd",
   "metadata": {},
   "source": [
    "### New approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d01e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr, y_arr = np.meshgrid(xx, yy)\n",
    "window = normalize(1 - np.sqrt(x_arr ** 2 + y_arr ** 2))\n",
    "window = window\n",
    "\n",
    "windowed_img = window * img\n",
    "window_ft = find_ft_2d(window)\n",
    "windowed_img_ft = find_ft_2d(windowed_img)\n",
    "  \n",
    "magn_windowed = np.abs(windowed_img_ft)\n",
    "magn_n = normalize(magn_windowed)\n",
    "magn_l = np.log10(magn_n)\n",
    "phase_windowed = np.angle(windowed_img_ft)\n",
    "restored_img = find_ift_2d(magn_windowed * np.exp(1j * phase_windowed)).real\n",
    "\n",
    "vmin = np.min(windowed_img)\n",
    "vmax = np.max(windowed_img)\n",
    "\n",
    "f, ax = show_images(windowed_img, np.log10(magn_windowed), phase_windowed, restored_img, \n",
    "                    figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_img_ft = find_ft_2d(phase_windowed)\n",
    "m = np.abs(windowed_img_ft)\n",
    "a = np.angle(windowed_img_ft)\n",
    "\n",
    "whitenoise = np.random.normal(0, 1, img_shape)\n",
    "psd = m * m\n",
    "restored_phase = find_ift_2d(psd ** 0.5 * np.abs(whitenoise) * np.exp(1j * a)).real\n",
    "\n",
    "kernel = freq_pink_filter_2d(xx, yy, factor=0.5)\n",
    "cloud_hf = find_ift_2d(magn_windowed * np.exp(1j * restored_phase)).real\n",
    "a, b = lin_regression(cloud_hf, img)\n",
    "cloud_hf = a * cloud_hf + b\n",
    "\n",
    "f, ax = show_images(np.log10(m), restored_phase, cloud_hf, figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb2be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1 = 1.8\n",
    "alpha2 = 1.0\n",
    "alpha_x = 1.4\n",
    "alpha_y = 1.\n",
    "\n",
    "whitenoise = np.random.normal(0, 1, img_shape)\n",
    "whitenoise_fr = find_ft_2d(whitenoise)\n",
    "kernel = fit_clement(xx, yy, alpha1, alpha2, eta=0.5)\n",
    "cloud_lf = find_ift_2d(whitenoise_fr * kernel).real\n",
    "a, b = lin_regression(cloud_lf, img)\n",
    "cloud_lf = a * cloud_lf + b\n",
    "\n",
    "f, ax = show_images(np.log10(kernel), cloud_hf + 0.001 * cloud_lf, figsize=figsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0242ca7",
   "metadata": {},
   "source": [
    "### Defining an angle between X-axis and ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_exp = 2\n",
    "threshold = 9\n",
    "width_x = 3\n",
    "width_y = 0\n",
    "\n",
    "# Removing lines along X-axis to get better angle estimation \n",
    "min_magn = np.min(magn_windowed)\n",
    "fit_magn = np.log(magn_windowed / min_magn)\n",
    "fit_no_clip = fit_magn\n",
    "\n",
    "for w in range(-width_y, width_y):\n",
    "    fit_magn[:, y_shift + w] = fit_magn[:, y_shift + width_y] * 0\n",
    "\n",
    "for w in range(-width_x, width_x):\n",
    "    fit_magn[x_shift + w, :] = fit_magn[x_shift + width_x, :]\n",
    "\n",
    "# Clipping magnitude \n",
    "fit_magn = np.where(fit_magn < threshold, 0, fit_magn)\n",
    "fit_magn_max = np.exp(np.max(fit_magn))\n",
    "fit_magn = fit_magn / np.mean(fit_magn)\n",
    "\n",
    "# Defining slope with regression\n",
    "avg_xy = -np.sum(x * y * fit_magn ** weight_exp)\n",
    "avg_y2 = np.sum(y * y * fit_magn ** weight_exp)\n",
    "avg_z2 = np.sum(fit_magn ** weight_exp)\n",
    "a = avg_xy / avg_y2\n",
    "angle = np.arctan(-1 / a) * 180 / np.pi\n",
    "\n",
    "# Defining STD along the lines with the found slopes\n",
    "lperp2 = np.sum((x + a * y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "lpara2 = np.sum((a * x - y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "lperp = lperp2 ** 0.5\n",
    "lpara = lpara2 ** 0.5\n",
    "\n",
    "# Outputing results \n",
    "print(f'A = {a}')\n",
    "print(f'Angle = {angle}')\n",
    "print(f'Slope = {1 / a}')\n",
    "print(f'l_perp = {lperp}')\n",
    "print(f'l_para = {lpara}')\n",
    "print(f'l_perp corrected = {lperp2 ** 0.5}')\n",
    "\n",
    "# Defining lines with found slopes\n",
    "y_line = np.linspace(0.1 * y_size, 0.9 * y_size)\n",
    "x_line = -a * (y_line - y_shift) + x_shift\n",
    "# y_line = np.linspace(-0.3 * y_size, 0.3 * y_size)\n",
    "# x_line = -a * y_line\n",
    "\n",
    "# Defining gaussian approximation of clipped magnitude\n",
    "model_magn = np.exp(-(x + a * y) ** 2 / 2 / (lperp2) -(a * x - y) ** 2 / 2 / (lpara2))\n",
    "# model_magn = model_magn / np.mean(model_magn)\n",
    "\n",
    "# Plotting \n",
    "f, ax = show_images(fit_magn, model_magn)\n",
    "ax[0].plot(x_line, y_line)\n",
    "ax[1].plot(x_line, y_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_line = np.linspace(-0.3 * y_size, 0.3 * y_size)\n",
    "x_line = -a * y_line\n",
    "\n",
    "f = go.Figure()\n",
    "f.add_trace(go.Heatmap(x=xx, y=yy, z=fit_magn))\n",
    "f.add_trace(go.Scatter(x=x_line, y=y_line))\n",
    "f.update_yaxes(scaleanchor='x', scaleratio=1)\n",
    "f.update_layout(width=500, height=500)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = show_images(fit_magn, figsize=figsize_small)\n",
    "# ax[0].plot(x_line_para, y_line_para)\n",
    "# ax[0].plot(x_line_perp, y_line_perp, '--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776c3ad",
   "metadata": {},
   "source": [
    "### Regression along lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31339d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_line_len = int(max(img_shape) * 2 ** 0.5) + 1\n",
    "\n",
    "# Parallel line\n",
    "para_slope = -1 / a\n",
    "x_line_para = np.linspace(0, x_size, x_size, endpoint=False)\n",
    "y_line_para = para_slope * (x_line_para - x_size // 2) + y_size // 2\n",
    "\n",
    "# Clipping arrays\n",
    "x_line_para, y_line_para = clip_graph(x_line_para, y_line_para, x_max=x_size, y_max=y_size)\n",
    "\n",
    "# Making arrays to have the same shape as original array\n",
    "x_line_min, x_line_max = int(np.min(x_line_para)), int(np.max(x_line_para))\n",
    "x_line_para = np.linspace(x_line_min, x_line_max, max_line_len, endpoint=False)\n",
    "y_line_para = para_slope * (x_line_para - x_size // 2) + y_size // 2\n",
    "\n",
    "# Perpendicular line \n",
    "perp_slope = -1 / para_slope\n",
    "x_line_perp = np.linspace(0, x_size, x_size, endpoint=False)\n",
    "y_line_perp = perp_slope * (x_line_perp - x_size // 2) + y_size // 2\n",
    "\n",
    "# Clipping arrays\n",
    "x_line_perp, y_line_perp = clip_graph(x_line_perp, y_line_perp, x_max=x_size, y_max=y_size)\n",
    "x_line_min, x_line_max = int(np.min(x_line_perp)) + 1, int(np.max(x_line_perp))\n",
    "x_line_perp = np.linspace(x_line_min, x_line_max, max_line_len, endpoint=False)\n",
    "y_line_perp = perp_slope * (x_line_perp - x_size // 2) + y_size // 2\n",
    "\n",
    "# Plotting\n",
    "f, ax = show_images(magn_l, cmap='gray', figsize=figsize_small)\n",
    "ax[0].plot(x_line_para, y_line_para)\n",
    "ax[0].plot(x_line_perp, y_line_perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c11cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1D regression along para line ORIGINAL APPROACH \n",
    "x_indexes_para = np.around(x_line_para).astype(int)\n",
    "y_indexes_para = np.around(y_line_para).astype(int)\n",
    "\n",
    "x_vals_para = np.hypot(x_line_para - x_shift, y_line_para - y_shift)\n",
    "y_vals_para = magn_n[y_indexes_para, x_indexes_para]\n",
    "\n",
    "max_val = np.max(y_vals_para)\n",
    "mid = find_index_by_val(y_vals_para, max_val)\n",
    "x_vals_para = x_vals_para[mid:]\n",
    "y_vals_para = y_vals_para[mid:]\n",
    "\n",
    "# Regression variables\n",
    "x_log_para = np.log(1 + x_vals_para)\n",
    "y_log_para = np.log(y_vals_para)\n",
    "alpha_para = -2 * np.sum(y_log_para * x_log_para) / np.sum(x_log_para ** 2) \n",
    "alpha_para = alpha_para / 2 \n",
    "\n",
    "para_approx = (1 + np.linspace(0, np.max(x_vals_para), x_vals_para.size)) ** (-alpha_para)\n",
    "# para_approx /= np.max(para_approx)\n",
    "\n",
    "plt.plot(x_vals_para, y_vals_para)\n",
    "plt.plot(x_vals_para, para_approx)\n",
    "plt.yscale('log')\n",
    "\n",
    "print(f'Mid = {mid}')\n",
    "print(f'Fade para = {alpha_para}')\n",
    "print(f'Arr max = {max_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(x_vals_para, 10 * np.log10(para_approx))\n",
    "plt.semilogx(x_vals_para, 10 * np.log10(y_vals_para))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0cd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1D regression along para line NEW APPROACH \n",
    "line_mid = x_line_para.size // 2\n",
    "x_indexes_para_n = np.around(x_line_para[line_mid:]) #.astype(int)\n",
    "y_indexes_para_n = np.around(y_line_para[line_mid:]) #.astype(int)\n",
    "\n",
    "x_vals_para_n = np.hypot(x_line_para - x_shift, y_line_para - y_shift)\n",
    "x_vals_para_n = x_vals_para_n[line_mid:]\n",
    "y_vals_para_n = get_slice(magn_n, y_indexes_para_n, x_indexes_para_n) # magn_n[y_indexes_para_n, x_indexes_para_n]\n",
    "\n",
    "max_val = np.max(y_vals_para_n)\n",
    "mid = find_index_by_val(y_vals_para_n, max_val)\n",
    "x_vals_para_n = x_vals_para_n[mid:]\n",
    "y_vals_para_n = y_vals_para_n[mid:]\n",
    "\n",
    "# Regression variables\n",
    "x_log_para_n = np.log(1 + x_vals_para_n)\n",
    "y_log_para_n = np.log(y_vals_para_n)\n",
    "alpha_para = -2 * np.sum(y_log_para_n * x_log_para_n) / np.sum(x_log_para_n ** 2) \n",
    "alpha_para = alpha_para / 2 \n",
    "\n",
    "para_approx = (1 + np.linspace(0, np.max(x_vals_para_n), x_vals_para_n.size)) ** (-alpha_para)\n",
    "# para_approx /= np.max(para_approx)\n",
    "\n",
    "plt.plot(x_vals_para_n, y_vals_para_n)\n",
    "plt.plot(x_vals_para_n, para_approx)\n",
    "plt.yscale('log')\n",
    "\n",
    "print(f'Mid = {mid}')\n",
    "print(f'Fade para = {alpha_para}')\n",
    "print(f'Arr max = {max_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1D regression along perp line ORIGINAL APPROACH \n",
    "x_indexes_perp = np.around(x_line_perp).astype(int)\n",
    "y_indexes_perp = np.around(y_line_perp).astype(int)\n",
    "\n",
    "x_vals_perp = np.hypot(x_line_perp - x_shift, y_line_perp - y_shift)\n",
    "y_vals_perp = magn_n[y_indexes_perp, x_indexes_perp]\n",
    "\n",
    "max_val = np.max(y_vals_perp)\n",
    "mid = find_index_by_val(y_vals_perp, max_val)\n",
    "x_vals_perp = x_vals_perp[mid:]\n",
    "y_vals_perp = y_vals_perp[mid:]\n",
    "\n",
    "# Regression variables\n",
    "x_log_perp = np.log(1 + x_vals_perp)\n",
    "y_log_perp = np.log(y_vals_perp)\n",
    "alpha_perp = -2 * np.sum(y_log_perp * x_log_perp) / np.sum(x_log_perp ** 2) \n",
    "alpha_perp = alpha_perp / 2 \n",
    "\n",
    "perp_approx = (1 + np.linspace(0, np.max(x_vals_perp), x_vals_perp.size)) ** (-alpha_perp)\n",
    "# perp_approx /= np.max(perp_approx)\n",
    "\n",
    "plt.plot(x_vals_perp, y_vals_perp)\n",
    "plt.plot(x_vals_perp, perp_approx)\n",
    "plt.yscale('log')\n",
    "\n",
    "print(f'Mid = {mid}')\n",
    "print(f'Fade pero = {alpha_perp}')\n",
    "print(f'Arr max = {max_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676eb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_mid = x_line_perp.size // 2\n",
    "x_indexes_perp_n = np.around(x_line_perp[line_mid:])\n",
    "y_indexes_perp_n = np.around(y_line_perp[line_mid:])\n",
    "\n",
    "x_vals_perp_n = np.hypot(x_line_perp - x_shift, y_line_perp - y_shift)\n",
    "x_vals_perp_n = x_vals_perp_n[line_mid:]\n",
    "y_vals_perp_n = get_slice(magn_n, y_indexes_perp_n, x_indexes_perp_n)\n",
    "\n",
    "max_val = np.max(y_vals_perp_n)\n",
    "mid = find_index_by_val(y_vals_perp_n, max_val)\n",
    "x_vals_perp_n = x_vals_perp_n[mid:]\n",
    "y_vals_perp_n = y_vals_perp_n[mid:]\n",
    "\n",
    "# Regression variables\n",
    "x_log_perp = np.log(1 + x_vals_perp_n)\n",
    "y_log_perp = np.log(y_vals_perp_n)\n",
    "alpha_perp = -2 * np.sum(y_log_perp * x_log_perp) / np.sum(x_log_perp ** 2) \n",
    "alpha_perp = alpha_perp / 2 \n",
    "\n",
    "perp_approx = (1 + np.linspace(0, np.max(x_vals_perp_n), x_vals_perp_n.size)) ** (-alpha_perp)\n",
    "# perp_approx /= np.max(perp_approx)\n",
    "\n",
    "plt.plot(x_vals_perp_n, y_vals_perp_n)\n",
    "plt.plot(x_vals_perp_n, perp_approx)\n",
    "plt.yscale('log')\n",
    "\n",
    "print(f'Mid = {mid}')\n",
    "print(f'Fade para = {alpha_perp}')\n",
    "print(f'Arr max = {max_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc37cb",
   "metadata": {},
   "source": [
    "### Defining best fit enumerating parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4462dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three pararmeters fit\n",
    "min_error = 10 ** 10\n",
    "alpha_steps = 50\n",
    "eta_steps = 50\n",
    "\n",
    "alphas = list(np.linspace(1, 2, alpha_steps))\n",
    "etas = list(np.linspace(0, 1, eta_steps))\n",
    "slopes = list(np.linspace(0.9 * -1 / a, 1.1 * -1 / a, 10))\n",
    "errors = np.zeros((alpha_steps, eta_steps))\n",
    "\n",
    "power = 1\n",
    "g = np.ones_like(img) # 0.5 * gaussian_new(x, y, max(lpara, lperp)) + 0.5\n",
    "#gaussian(x, para_slope * y, lpara2_new ** 0.5) * gaussian(para_slope * x, -y, lperp2_new ** 0.5)\n",
    "weight = g ** power\n",
    "\n",
    "for k, slope in enumerate(slopes):\n",
    "    print_progress_bar(k + 1, len(slopes), prefix = 'Progress:', suffix = 'Complete', length=50)\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        for j, eta in enumerate(etas):\n",
    "            my_fit = np.log10(fit_clement_new(xx, yy, alpha, eta=eta, slope=slope))\n",
    "            error = rmse(magn_l, my_fit, weight, normalize=True)\n",
    "            errors[i, j] = error\n",
    "            \n",
    "            if min_error > error:\n",
    "                min_error = error\n",
    "                min_params = (slope, alpha, eta)\n",
    "                best_fit = my_fit\n",
    "\n",
    "write_file(output_dir + outp_filename, errors)\n",
    "print(*min_params, min_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two pararmeters fit\n",
    "min_error = 10 ** 10\n",
    "alpha_steps = 50\n",
    "eta_steps = 50\n",
    "\n",
    "alphas = list(np.linspace(1, 2, alpha_steps))\n",
    "etas = list(np.linspace(0, 1, eta_steps))\n",
    "errors = np.zeros((alpha_steps, eta_steps))\n",
    "\n",
    "power = 1\n",
    "g = np.ones_like(img) # 0.5 * gaussian_new(x, y, max(lpara, lperp)) + 0.5\n",
    "#gaussian(x, para_slope * y, lpara2_new ** 0.5) * gaussian(para_slope * x, -y, lperp2_new ** 0.5)\n",
    "weight = g ** power\n",
    "\n",
    "    \n",
    "for i, alpha in enumerate(alphas):\n",
    "    print_progress_bar(i + 1, len(alphas), prefix = 'Progress:', suffix = 'Complete', length=50)\n",
    "    for j, eta in enumerate(etas):\n",
    "        my_fit = np.log10(fit_clement_new(xx, yy, alpha, eta=eta, slope=para_slope))\n",
    "        error = rmse(magn_l, my_fit, weight, normalize=True)\n",
    "        errors[i, j] = error\n",
    "            \n",
    "        if min_error > error:\n",
    "            min_error = error\n",
    "            min_params = (alpha, eta)\n",
    "            best_fit = my_fit\n",
    "    \n",
    "print(*min_params, min_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = show_images(errors, figsize=figsize_small)\n",
    "ax[-1].scatter([min_params[1] * eta_steps], [(min_params[0] - 1) * alpha_steps])\n",
    "ax[-1].scatter([stretch_factor * eta_steps], [(alpha_perp - 1) * alpha_steps])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7792b",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = magn\n",
    "x_vals = freq_filter_2d(xx, yy)\n",
    "\n",
    "y_log = np.log10(y_vals)\n",
    "x_log = np.log10(1 + x_vals)\n",
    "\n",
    "alpha = -np.sum(y_log * x_log) / np.sum(x_log ** 2) \n",
    "tr_kernel = freq_pink_filter_2d(xx, yy, factor=alpha)\n",
    "tr_kernel_factor = normalize_psd(magn_raw, tr_kernel)\n",
    "print(f'Traditional approach alpha = {alpha}')\n",
    "\n",
    "tr_image = find_ift_2d(tr_kernel_factor * tr_kernel * np.exp(1j * phase_windowed)) \n",
    "a, b = lin_regression(tr_image, img)\n",
    "tr_image = a * tr_image + b\n",
    "\n",
    "r_kernel = fit_clement_new(xx, yy, alpha_perp, slope=para_slope, eta=alpha_perp / alpha_para - 1)\n",
    "r_kernel_factor = normalize_psd(magn_raw, r_kernel)\n",
    "r_image = find_ift_2d(r_kernel_factor * r_kernel * np.exp(1j * phase))\n",
    "a, b = lin_regression(r_image, img)\n",
    "r_image = a * r_image + b\n",
    "\n",
    "print(r_err := rmse(img, r_image))\n",
    "print(tr_err := rmse(img, tr_image))\n",
    "print(abs(r_err - tr_err) / tr_err * 100)\n",
    "\n",
    "show_images(tr_image, r_image, vrange=(vmin, vmax), figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.4\n",
    "\n",
    "phase_ft = find_ft_2d(phase_windowed)\n",
    "m = np.abs(phase_ft)\n",
    "ang = np.angle(phase_ft)\n",
    "\n",
    "whitenoise = np.random.normal(0, 1, img_shape)\n",
    "whitenoise_fr = find_ft_2d(whitenoise)\n",
    "random_phase = np.angle(whitenoise_fr)\n",
    "\n",
    "ff = 1\n",
    "ps = normalize(freq_filter_2d(xx, yy))\n",
    "p = 1\n",
    "\n",
    "phase_kernel = np.abs(m)\n",
    "norm = normalize_psd(m, phase_kernel * ff * p)\n",
    "restored_phase = find_ift_2d(norm * phase_kernel * ff * p * np.exp(1j * ang)).real\n",
    "restored_phase = (1 - eps) * restored_phase  + eps * random_phase\n",
    "\n",
    "restored_kernel = fit_clement_new(xx, yy, alpha_perp, eps, para_slope)\n",
    "restored_kernel_factor = normalize_psd(magn_raw, restored_kernel)\n",
    "restored_img_3 = find_ift_2d(restored_kernel_factor * restored_kernel * np.exp(1j * restored_phase))\n",
    "#a, b = lin_regression(restored_img_3, img)\n",
    "#restored_img_3 = a * restored_img_3 + b\n",
    "\n",
    "show_images(restored_img_3, vrange=(vmin, vmax), figsize=figsize_small)\n",
    "# show_images(restored_img_3, img, restored_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5)\n",
    "y_raw = 2 * np.linspace(-5, 5) \n",
    "y = y_raw + np.random.normal(0, 5, x.shape)\n",
    "\n",
    "plt.plot(x, y_raw)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_x2 = np.sum(x * x)\n",
    "sum_y2 = np.sum(y * y)\n",
    "sum_xy = np.sum(x * y)\n",
    "\n",
    "slope_x = sum_xy / sum_x2\n",
    "slope_y = sum_xy / sum_y2\n",
    "\n",
    "print(f'Slope x = {slope_x}')\n",
    "print(f'Slope y = {slope_y}')\n",
    "\n",
    "x_vals = np.linspace(-5, 5) \n",
    "y_vals = np.linspace(-5, 5) \n",
    "\n",
    "plt.plot(x_vals, slope_x * x_vals)\n",
    "plt.plot(slope_y * x_vals, x_vals)\n",
    "plt.plot(x, y)\n",
    "# plt.plot(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998306f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = show_images(x * y * fit_magn ** weight_exp, \n",
    "                    x * x * fit_magn ** weight_exp, \n",
    "                    y * y * fit_magn ** weight_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a19334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "indexes = fit_magn >= threshold\n",
    "x, y = [], []\n",
    "\n",
    "for row in range(indexes.shape[0]):\n",
    "    for col in range(indexes.shape[1]):\n",
    "        if indexes[row, col]:\n",
    "            y.append(row)\n",
    "            x.append(col)\n",
    "            \n",
    "\n",
    "x_centered = x - np.mean(x)\n",
    "y_centered = y - np.mean(y)\n",
    "\n",
    "# Create the centered matrix\n",
    "data_centered = np.vstack([x_centered, y_centered])\n",
    "\n",
    "# Compute the covariance matrix\n",
    "cov_matrix = np.cov(data_centered)\n",
    "\n",
    "# Compute the eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort the eigenvalues and eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues_sorted = eigenvalues[sorted_indices]\n",
    "eigenvectors_sorted = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# The eigenvectors are now the directions of the axes of the ellipse,\n",
    "# with the largest eigenvalue corresponding to the major axis.\n",
    "major_axis = eigenvectors_sorted[:, 0]\n",
    "minor_axis = eigenvectors_sorted[:, 1]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Major Axis: {major_axis}\")\n",
    "print(f\"Minor Axis: {minor_axis}\")\n",
    "\n",
    "fig, ax = show_images(fit_magn)\n",
    "ax[-1].plot([x_shift, x_shift + 300 * major_axis[0]], [y_shift, y_shift + 300 * major_axis[-1]])\n",
    "ax[-1].plot([x_shift, x_shift + 300 * minor_axis[0]], [y_shift, y_shift + 300 * minor_axis[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_exp = 2\n",
    "threshold = 9\n",
    "width_x = 3\n",
    "width_y = 0\n",
    "x, y = np.meshgrid(xx, yy)\n",
    "\n",
    "# Removing lines along X-axis to get better angle estimation \n",
    "min_magn = np.min(magn_windowed[np.nonzero(magn_windowed)])\n",
    "fit_magn = np.log(magn_windowed / min_magn)\n",
    "fit_no_clip = fit_magn\n",
    "\n",
    "for w in range(-width_y, width_y):\n",
    "    fit_magn[:, y_shift + w] = fit_magn[:, y_shift + width_y] * 0\n",
    "\n",
    "for w in range(-width_x, width_x):\n",
    "    fit_magn[x_shift + w, :] = fit_magn[x_shift + width_x, :]\n",
    "\n",
    "# Clipping magnitude \n",
    "fit_magn = np.where(fit_magn < threshold, 0, fit_magn)\n",
    "fit_magn = fit_magn / np.mean(fit_magn)\n",
    "\n",
    "# Defining slope with regression\n",
    "avg_xy = np.sum(x * y * fit_magn ** weight_exp)\n",
    "avg_x2 = np.sum(x * x * fit_magn ** weight_exp)\n",
    "avg_y2 = np.sum(y * y * fit_magn ** weight_exp)\n",
    "slope = avg_xy / avg_y2\n",
    "# slope = avg_xy / avg_x2\n",
    "\n",
    "# Outputing results \n",
    "print(f'Slope = {slope}')\n",
    "\n",
    "# Defining lines with found slopes\n",
    "y_line = np.linspace(-0.3 * y_size, 0.3 * y_size)\n",
    "x_line = slope * y_line\n",
    "#x_line = np.linspace(-0.3 * x_size, 0.3 * x_size)\n",
    "#y_line = slope * x_line\n",
    "\n",
    "f = go.Figure()\n",
    "f.add_trace(go.Heatmap(x=xx, y=yy, z=fit_magn, colorscale='greys_r'))\n",
    "f.add_trace(go.Scatter(x=x_line, y=y_line))\n",
    "f.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "f.update_layout(width=500, height=500)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31262d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining STD along the lines with the found slopes\n",
    "lperp2 = np.sum((x + a * y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "lpara2 = np.sum((a * x - y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "lperp = lperp2 ** 0.5\n",
    "lpara = lpara2 ** 0.5\n",
    "\n",
    "# Outputing results \n",
    "print(f'A = {a}')\n",
    "print(f'Angle = {angle}')\n",
    "print(f'Slope = {1 / a}')\n",
    "print(f'l_perp = {lperp}')\n",
    "print(f'l_para = {lpara}')\n",
    "print(f'l_perp corrected = {lperp2 ** 0.5}')\n",
    "\n",
    "# Defining lines with found slopes\n",
    "y_line = np.linspace(0.1 * y_size, 0.9 * y_size)\n",
    "x_line = -a * (y_line - y_shift) + x_shift\n",
    "# y_line = np.linspace(-0.3 * y_size, 0.3 * y_size)\n",
    "# x_line = -a * y_line\n",
    "\n",
    "# Defining gaussian approximation of clipped magnitude\n",
    "model_magn = np.exp(-(x + a * y) ** 2 / 2 / (lperp2) -(a * x - y) ** 2 / 2 / (lpara2))\n",
    "# model_magn = model_magn / np.mean(model_magn)\n",
    "\n",
    "# Plotting \n",
    "f, ax = show_images(fit_magn, model_magn, (x + a * y) ** 2 * fit_magn ** weight_exp, (a * x - y) ** 2 * fit_magn ** weight_exp)\n",
    "ax[0].plot(x_line, y_line)\n",
    "ax[1].plot(x_line, y_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x_vals, y_vals, std):\n",
    "    arg = x_vals + y_vals \n",
    "    exp = np.exp(-arg ** 2 / (2 * std ** 2))\n",
    "    return exp\n",
    "\n",
    "\n",
    "def gaussian_new(x_vals, y_vals, std):\n",
    "    exp = np.exp(-(x_vals ** 2 + y_vals ** 2) / (2 * std ** 2))\n",
    "    return exp\n",
    "\n",
    "\n",
    "def fit(x_freq, y_freq, alpha1, eta=0.1, angle=1):\n",
    "    x, y = np.meshgrid(x_freq, y_freq)\n",
    "    f = np.hypot(x, y)\n",
    "    fp = abs(y - angle * x)\n",
    "    f = np.sqrt((1 - eta) * f ** 2 + eta * fp ** 2)\n",
    "    f = 1 / ((1 + abs(f)) ** alpha1)\n",
    "    return f\n",
    "\n",
    "\n",
    "def read_file(filename, sep=',', outp_type=None):\n",
    "    data = []\n",
    "    outp_type = str if outp_type is None else outp_type\n",
    "    \n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            line = [outp_type(col.strip()) for col in line.split(sep)]\n",
    "            data.append(line)\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_file(filename, arr, sep=','):\n",
    "    with open(filename, 'w') as file:\n",
    "        for line in arr:\n",
    "            line_str = [str(i) for i in line]\n",
    "            file.write(sep.join(line_str) + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lperp2 = np.sum((x + a * y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "lpara2 = np.sum((a * x - y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "lpara2_new = np.sum((para_slope * x - y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "lperp2_new = np.sum((perp_slope * x - y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "\n",
    "perp_my = np.exp(-(x + para_slope * y) ** 2 / 2 / lpara2_new)\n",
    "para_my = np.exp(-(para_slope * x - y) ** 2 / 2 / lperp2_new)\n",
    "\n",
    "z1 = np.exp(-(x + a * y) ** 2 / 2 / (lperp2))\n",
    "z2 = np.exp(-(a * x - y) ** 2 / 2 / (lpara2))\n",
    "z3 = np.exp(-(x + a * y) ** 2 / 2 / (lperp2) -(a * x - y) ** 2 / 2 / (lpara2))\n",
    "z4 = gaussian_new(para_slope * x, -y, lperp2_new ** 0.5) * gaussian_new(x, para_slope * y, lpara2_new ** 0.5) \n",
    "z5 = np.exp(-(para_slope * x - y) ** 2 / 2 / (lpara2_new) -(perp_slope * x - y) ** 2 / 2 / (lperp2_new))\n",
    "\n",
    "show_images(z3, z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining optimal alpha and eta values that minimize approximation error \n",
    "\n",
    "# Factor that represents how stretched ellipse along its major axis\n",
    "stretch_factor = (alpha_perp / alpha_para) - 1\n",
    "magn_n = normalize(magn_windowed)\n",
    "magn_l = np.log10(magn_n)\n",
    "std = np.std(magn_windowed)\n",
    "\n",
    "print(f'Stretch = {stretch_factor}', f'\\nSTD = {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54528f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original stretched gaussian\n",
    "\n",
    "perp_gaussian = np.exp(-(a * x - y) ** 2 / 2 / (lpara2))\n",
    "para_gaussian = np.exp(-(x + a * y) ** 2 / 2 / (lperp2))\n",
    "\n",
    "perp_my = np.exp(-(perp_slope * x - y) ** 2 / (2 * lpara2))\n",
    "para_my = np.exp(-(x + perp_slope * y) ** 2 / (2 * lperp2))\n",
    "\n",
    "\"\"\"\n",
    "f, ax = show_images(perp_my, para_my, perp_my * para_my, figsize=figsize)\n",
    "ax.flatten()[0].plot(x_line_para, y_line_para)\n",
    "ax.flatten()[0].plot(x_line_perp, y_line_perp)\n",
    "ax.flatten()[1].plot(x_line_para, y_line_para)\n",
    "ax.flatten()[1].plot(x_line_perp, y_line_perp)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "print(1 / (lpara2 / lperp2) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48987bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = gaussian_new(x, para_slope * y, lperp) \n",
    "g2 = gaussian_new(para_slope * x, -y, lperp)\n",
    "g = np.exp(-(x **2 + y ** 2) / (2 * lpara2))\n",
    "g_n = gaussian_new(x, y, max(lpara, lperp))\n",
    "\n",
    "# show_images(g1, g2, g, g_n, model_magn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreating stretched gaussian in a different manner \n",
    "\n",
    "lperp2_new = np.sum((para_slope * x - y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "lpara2_new = np.sum((x + para_slope * y) ** 2 * fit_magn ** weight_exp) / avg_z2\n",
    "\n",
    "# perp_my = np.exp(-(x + para_slope * y) ** 2 / 2 / lpara2_new)\n",
    "# para_my = np.exp(-(para_slope * x - y) ** 2 / 2 / lperp2_new)\n",
    "\n",
    "# f, ax = show_images(perp_my, para_my, perp_my * para_my, gaussian(x, para_slope * y, lperp) * gaussian(para_slope * x, -y, lperp), figsize=figsize)\n",
    "# plt.plot()\n",
    "\n",
    "print((lpara2_new / lperp2_new) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f03c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error = 10 ** 10\n",
    "alpha_steps = 50\n",
    "eta_steps = 50\n",
    "\n",
    "angle = para_slope\n",
    "alphas = list(np.linspace(1, 2, alpha_steps))\n",
    "etas = list(np.linspace(0, 1, eta_steps))\n",
    "errors = np.zeros((alpha_steps, eta_steps))\n",
    "\n",
    "power = 1\n",
    "g = 0.5 * gaussian_new(x, y, max(lpara, lperp)) + 0.5\n",
    "#gaussian(x, para_slope * y, lpara2_new ** 0.5) * gaussian(para_slope * x, -y, lperp2_new ** 0.5)\n",
    "weight = g ** power\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    print_progress_bar(i + 1, alpha_steps, prefix = 'Progress:', suffix = 'Complete', length=50)\n",
    "    for j, eta in enumerate(etas):\n",
    "        my_fit = np.log10(fit_clement_new(xx, yy, alpha, eta=eta, angle=angle))\n",
    "        error = rmse(magn_l, my_fit, weight, normalize=True)\n",
    "        errors[i, j] = error\n",
    "    \n",
    "        if min_error > error:\n",
    "            min_error = error\n",
    "            min_params = (alpha, eta)\n",
    "            best_fit = my_fit\n",
    "    \n",
    "print(*min_params, min_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522fa0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretch = 1 - (alpha_para / alpha_perp)\n",
    "print(stretch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bff260",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.log(fit_clement_new(xx, yy, 1, 0))\n",
    "bb = np.log(fit_clement_new(xx, yy, 1, 1))\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "ax.contour(aa)\n",
    "ax.contour(bb)\n",
    "plt.gca().set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_surfaces((etas, alphas, errors))\n",
    "\n",
    "f, ax = show_images(errors)\n",
    "ax[-1].scatter([50 * 0.08163265306122448], [50 * (1.5510204081632653 - 1)])\n",
    "ax[-1].scatter([50 * 0.09926537681351011], [50 * (alpha_perp - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844067ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fit = np.log10(fit_clement_new(xx, yy, 1.5912427219379994, eta=0.09030864630077595, angle=angle))\n",
    "error = rmse(magn_l, my_fit)\n",
    "\n",
    "show_surfaces(my_fit, axes=(xx, yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters values that minimizes RMSE vs different weighting fuctions \n",
    "\n",
    "# alpha / eta / rmse / weighting function used \n",
    "1.530612244897959 0.1836734693877551 0.3170742184535750 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1/16\n",
    "1.510204081632653 0.3061224489795918 0.3141849150420232 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1/8\n",
    "1.510204081632653 0.4285714285714286 0.3059434597361637 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1/4\n",
    "1.489795918367347 0.5102040816326531 0.2980129494208664 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1/2\n",
    "1.551020408163265 0.0816326530612245 0.3101641380512348 - stretch_factor gaussian, lperp2_new, lpara2_new, power 0\n",
    "1.489795918367347 0.5510204081632653 0.2963893721718555 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1\n",
    "1.489795918367347 0.5918367346938775 0.2988267656442404 - stretch_factor gaussian, lperp2_new, lpara2_new, power 2\n",
    "1.469387755102041 0.6122448979591836 0.3010629882540416 - stretch_factor gaussian, lperp2_new, lpara2_new, power 4\n",
    "1.448979591836735 0.6530612244897959 0.3014733363273698 - stretch_factor gaussian, lperp2_new, lpara2_new, power 8\n",
    "1.408163265306123 0.6530612244897959 0.3001330362656289 - stretch_factor gaussian, lperp2_new, lpara2_new, power 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a334b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error = 10 ** 10\n",
    "eta_steps = 1000\n",
    "\n",
    "alpha = alpha_perp\n",
    "angle = para_slope\n",
    "\n",
    "etas = list(np.linspace(0, 1, eta_steps))\n",
    "errors = np.zeros((eta_steps))\n",
    "\n",
    "power = 1\n",
    "g = model_magn\n",
    "# gaussian(x, para_slope * y, lpara2_new) * gaussian(para_slope * x, -y, lperp2_new) * 0.5 + 0.5\n",
    "weight = g ** power\n",
    "\n",
    "for i, eta in enumerate(etas):\n",
    "    print_progress_bar(i + 1, eta_steps, prefix = 'Progress:', suffix = 'Complete', length=50)\n",
    "    my_fit = np.log10(fit_clement_new(xx, yy, alpha, eta=eta, angle=angle))\n",
    "    error = rmse(magn_l, my_fit, normalize=True)\n",
    "    errors[i] = error\n",
    "    \n",
    "    if min_error > error:\n",
    "        min_error = error\n",
    "        min_params = eta\n",
    "        best_fit = my_fit\n",
    "\n",
    "print(min_params, min_error)\n",
    "plt.plot(etas, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eafcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = show_surfaces(magn_l, np.log10(fit_clement_new(xx, yy, alpha_perp, eta=0.1, angle=angle)), \n",
    "                  axes=(xx, yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f632253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter ETA values that minimizes RMSE vs different weighting fuctions \n",
    "\n",
    "# eta / rmse / weighting function used \n",
    "0.2242242242242242 0.3265342020042337 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1/16\n",
    "0.2922922922922923 0.3186435287660681 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1/8\n",
    "0.4094094094094094 0.3070339788163856 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1/4\n",
    "0.5115115115115115 0.2979411915626497 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1/2\n",
    "0.2402402402402402 0.3283416593400807 - stretch_factor gaussian, lperp2_new, lpara2_new, power 0\n",
    "0.5625625625625625 0.2963620999748029 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1\n",
    "0.6026026026026026 0.2988631732452551 - stretch_factor gaussian, lperp2_new, lpara2_new, power 2\n",
    "0.6526526526526526 0.3027102264219166 - stretch_factor gaussian, lperp2_new, lpara2_new, power 4\n",
    "0.7047047047047047 0.3074197765466930 - stretch_factor gaussian, lperp2_new, lpara2_new, power 8\n",
    "0.7507507507507507 0.3159201546790819 - stretch_factor gaussian, lperp2_new, lpara2_new, power 16\n",
    "\n",
    "0.2442442442442442 0.3280924429943492 - stretch_factor gaussian, lperp2_new, lpara2_new, power 1, *0.5 + 0.5 \n",
    "0.2402402402402402 0.3283416593400807 - stretch_factor gaussian, lperp2_new, no weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = show_images(magn_l, np.log10(fit_clement_new(xx, yy, alpha, eta=0.2442442442442442, angle=angle)))\n",
    "ax[-1].plot(x_line_para, y_line_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a33fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = show_surfaces(np.log10(fit_clement_new(xx, yy, alpha, eta=0.2442442442442442, angle=angle)), magn_l, axes=(xx, yy))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stretching gaussain along axes\n",
    "# Define the size of the kernel and standard deviation\n",
    "kernel_size = 21\n",
    "sigma = 2.0\n",
    "\n",
    "# Create a standard 2D Gaussian kernel\n",
    "x = np.linspace(-kernel_size // 2, kernel_size // 2, kernel_size)\n",
    "y = np.linspace(-kernel_size // 2, kernel_size // 2, kernel_size)\n",
    "x, y = np.meshgrid(x, y)\n",
    "kernel = np.exp(-(x**2 + y**2) / (2.0 * sigma**2))\n",
    "\n",
    "# Create a scaling factor for stretching along y = x\n",
    "stretching_factor = 2.0  # Adjust this value to control the stretching\n",
    "new_x = stretching_factor * x\n",
    "\n",
    "# Create the stretched Gaussian kernel\n",
    "stretched_kernel = np.exp(-(new_x**2 + y**2) / (2.0 * sigma**2))\n",
    "\n",
    "# Display the original and stretched kernels\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(kernel, cmap='viridis')\n",
    "plt.title('Original Gaussian Kernel')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(stretched_kernel, cmap='viridis')\n",
    "plt.title('Stretched Gaussian Kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c83697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some experiments\n",
    "# Blending whitenoise phase with original phase\n",
    "\n",
    "whitenoise = np.random.normal(0, 1, (x_size, y_size))\n",
    "whitenoise_fr = find_ft_2d(whitenoise)\n",
    "new_angle = np.angle(whitenoise_fr)\n",
    "\n",
    "width = 25 #img.shape[0] // 2 - 1\n",
    "step = 1\n",
    "\n",
    "for i in range(-width, width + 1, step):\n",
    "    new_angle[img.shape[0] // 2 + i, :] = phase_windowed[img.shape[0] // 2 + i, :]\n",
    "    \n",
    "for j in range(-width, width + 1, step):\n",
    "    new_angle[:, img.shape[1] // 2 + j] = phase_windowed[:, img.shape[1] // 2 + j]\n",
    "        \n",
    "        \n",
    "dunno = find_ift_2d(magn_windowed * np.exp(1j * new_angle)).real \n",
    "# f, ax = show_images(dunno / window)\n",
    "\n",
    "# sharp_filter = 1 - (freq_sharp_round_filter_2d(xx, yy, radius=900) - freq_sharp_round_filter_2d(xx, yy, radius=50))\n",
    "# dunno = find_ift_2d(sharp_filter * magn_windowed * np.exp(1j * phase_windowed)).real\n",
    "dunno = find_ift_2d(magn_windowed * np.exp(1j * new_angle)).real\n",
    "a, b = lin_regression(dunno, img)\n",
    "dunno = a * dunno + b\n",
    "\n",
    "f, ax = show_images(new_angle, dunno)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
