{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "from PIL import Image\n",
    "from os import getcwd\n",
    "from math import ceil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "input_dir = getcwd() + '/img/input_samples/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogates(x, ns, tol_pc=5., verbose=True, maxiter=1E6, sorttype=\"quicksort\"):\n",
    "    # as per the steps given in Lancaster et al., Phys. Rep (2018)\n",
    "    nx = x.shape[0]\n",
    "    xs = np.zeros((ns, nx))\n",
    "    maxiter = 10000\n",
    "    ii = np.arange(nx)\n",
    "\n",
    "    # get the fft of the original array\n",
    "    x_amp = np.abs(np.fft.fft(x))\n",
    "    x_srt = np.sort(x)\n",
    "    r_orig = np.argsort(x)\n",
    "\n",
    "    # loop over surrogate number\n",
    "    pb_fmt = \"{desc:<5.5}{percentage:3.0f}%|{bar:30}{r_bar}\"\n",
    "    pb_desc = \"Estimating IAAFT surrogates ...\"\n",
    "    for k in tqdm(range(ns), bar_format=pb_fmt, desc=pb_desc,\n",
    "                  disable=not verbose):\n",
    "\n",
    "        # 1) Generate random shuffle of the data\n",
    "        count = 0\n",
    "        r_prev = np.random.permutation(ii)\n",
    "        r_curr = r_orig\n",
    "        z_n = x[r_prev]\n",
    "        percent_unequal = 100.\n",
    "\n",
    "        # core iterative loop\n",
    "        while (percent_unequal > tol_pc) and (count < maxiter):\n",
    "            r_prev = r_curr\n",
    "\n",
    "            # 2) FFT current iteration yk, and then invert it but while\n",
    "            # replacing the amplitudes with the original amplitudes but\n",
    "            # keeping the angles from the FFT-ed version of the random\n",
    "            y_prev = z_n\n",
    "            fft_prev = np.fft.fft(y_prev)\n",
    "            phi_prev = np.angle(fft_prev)\n",
    "            e_i_phi = np.exp(phi_prev * 1j)\n",
    "            z_n = np.fft.ifft(x_amp * e_i_phi)\n",
    "\n",
    "            # 3) rescale zk to the original distribution of x\n",
    "            r_curr = np.argsort(z_n, kind=sorttype)\n",
    "            z_n[r_curr] = x_srt.copy()\n",
    "            percent_unequal = ((r_curr != r_prev).sum() * 100.) / nx\n",
    "\n",
    "            # 4) repeat until number of unequal entries between r_curr and \n",
    "            # r_prev is less than tol_pc percent\n",
    "            count += 1\n",
    "\n",
    "        if count >= (maxiter - 1):\n",
    "            print(\"maximum number of iterations reached!\")\n",
    "\n",
    "        xs[k] = np.real(z_n)\n",
    "\n",
    "    return xs\n",
    "\n",
    "\n",
    "def freq_filter(x_freq, y_freq, factor=2.4):\n",
    "    eps = 10 ** -8\n",
    "    x, y = np.meshgrid(x_freq, y_freq)\n",
    "    f = np.hypot(x, y)\n",
    "    f = f ** factor + eps\n",
    "    return normalize(1 / f)\n",
    "\n",
    "\n",
    "def freq_filter_2d(x_freq, y_freq, x_aspect=1, y_aspect=1, factor=1):\n",
    "    x, y = np.meshgrid(x_freq, y_freq)\n",
    "    f = np.hypot(x / x_aspect, y / y_aspect)\n",
    "    f = 1 / (1 + np.abs(f))\n",
    "    f = f ** (factor + 1)\n",
    "    return normalize(f)\n",
    "\n",
    "\n",
    "def freq_filter_1d(x_freq, factor=1):\n",
    "    f = 1 / (1 + np.abs(x_freq))\n",
    "    f = f ** factor\n",
    "    return f\n",
    "\n",
    "\n",
    "def freq_filter_1d_a(x_freq, factor=1):\n",
    "    f = 1 / np.where(x_freq == 0, 1, np.abs(x_freq))\n",
    "    f = f ** factor\n",
    "    f[len(x_freq) // 2] = 0\n",
    "    return f\n",
    "\n",
    "\n",
    "def freq_sharp_round_filter(x_freq, y_freq, radius, reverse=False):\n",
    "    eps = 10 ** -8\n",
    "    x, y = np.meshgrid(x_freq, y_freq)\n",
    "    if reverse:\n",
    "        f = np.zeros((x_size, y_size))\n",
    "    else:\n",
    "        f = np.ones((x_size, y_size))\n",
    "    \n",
    "    for i, xx in enumerate(x_freq):\n",
    "        for j, yy in enumerate(y_freq):\n",
    "            if xx ** 2 + yy ** 2 <= radius ** 2:\n",
    "                if reverse:\n",
    "                    f[i, j] = 1\n",
    "                else:\n",
    "                    f[i, j] = 0\n",
    "    return normalize(f)\n",
    "\n",
    "\n",
    "def freq_sharp_square_filter(x_freq, y_freq, width, reverse=False):\n",
    "    eps = 10 ** -8\n",
    "    x, y = np.meshgrid(x_freq, y_freq)\n",
    "    if reverse:\n",
    "        f = np.zeros((x_size, y_size))\n",
    "    else:\n",
    "        f = np.ones((x_size, y_size))\n",
    "    \n",
    "    for i, xx in enumerate(x_freq):\n",
    "        for j, yy in enumerate(y_freq):\n",
    "            if abs(xx) + abs(yy) <= width:\n",
    "                if reverse:\n",
    "                    f[i, j] = 1\n",
    "                else:\n",
    "                    f[i, j] = 0\n",
    "    return normalize(f)\n",
    "\n",
    "\n",
    "def spatial_smooth_filter(x_size, y_size, depth, horiz=True):\n",
    "    values = np.linspace(0, 1, depth)\n",
    "    values = 6 * values ** 5 - 15 * values ** 4 + 10 * values ** 3\n",
    "    values = 1 - values\n",
    "    if horiz:\n",
    "        kernel = np.tile(values, (y_size, 1))\n",
    "    else:\n",
    "        kernel = values[:, np.newaxis] * np.ones((1, x_size))   \n",
    "    return kernel\n",
    "\n",
    "\n",
    "def find_ft(img):\n",
    "    ft = np.fft.fft2(img)\n",
    "    return np.fft.fftshift(ft)\n",
    "\n",
    "\n",
    "def find_ft_1d(img):\n",
    "    ft = np.fft.fft(img)\n",
    "    return np.fft.fftshift(ft)\n",
    "\n",
    "\n",
    "def find_ift(ft):\n",
    "    ift = np.fft.ifftshift(ft)\n",
    "    return np.fft.ifft2(ift)\n",
    "\n",
    "\n",
    "def find_ift_1d(ft):\n",
    "    ift = np.fft.ifftshift(ft)\n",
    "    return np.fft.ifft(ift)\n",
    "\n",
    "\n",
    "def freq_numbers_1d(size):\n",
    "    if size % 2:\n",
    "        return np.arange(-(size // 2), size // 2 + 1, 1) \n",
    "    else:\n",
    "        return np.arange(-(size // 2), size // 2, 1) \n",
    "    \n",
    "\n",
    "def freq_1d(size, step=1):\n",
    "    freq = freq_numbers_1d(size) \n",
    "    return freq / step / size\n",
    "\n",
    "\n",
    "def adjust_freq_1d(img):\n",
    "    return np.append(img, abs(img[0]))\n",
    "\n",
    "\n",
    "def adjust_img_1d(img):\n",
    "    return np.append(img, img[0])\n",
    "        \n",
    "        \n",
    "def normalize(arr):\n",
    "    min_val = abs(np.min(arr))\n",
    "    max_val = abs(np.max(arr))\n",
    "    return (arr + min_val) / (min_val + max_val)\n",
    "\n",
    "\n",
    "def normalize(arr):\n",
    "    min_val = abs(np.min(arr))\n",
    "    max_val = abs(np.max(arr))\n",
    "    return (arr - 0.99 * min_val) / (max_val - 0.99 * min_val)\n",
    "\n",
    "\n",
    "def normalize_img(img):\n",
    "    img_min = abs(np.min(img))\n",
    "    img_max = abs(np.max(img))\n",
    "    img_norm = 255 * (img + img_min) / (img_min + img_max)\n",
    "    return img_norm.astype(int)\n",
    "\n",
    "\n",
    "def gen_cloud(x_size, y_size, factor=2.4):\n",
    "    xx = np.linspace(-x_size / 2, x_size / 2, x_size)\n",
    "    yy = np.linspace(-y_size / 2, y_size / 2, y_size)\n",
    "    whitenoise = np.random.normal(0, 1, (y_size, x_size))\n",
    "    cloud_freq = find_ft(whitenoise)  \n",
    "    kernel = freq_filter(xx, yy, factor=factor)\n",
    "    cloud_freq_filtered = cloud_freq * kernel\n",
    "    cloud_spatial = find_ift(cloud_freq_filtered).real\n",
    "    return normalize_img(cloud_spatial)\n",
    "\n",
    "\n",
    "def show_images(*images, vmin=0, vmax=255, x_fig_size=10, cmap='gray', y_fig_size=10, graphs_per_row=2):\n",
    "    row_num = ceil(len(images) / graphs_per_row)\n",
    "    col_num = ceil(len(images) / row_num)\n",
    "    \n",
    "    f, axes = plt.subplots(row_num, col_num, sharey=True, figsize=(x_fig_size, y_fig_size))\n",
    "\n",
    "    for ax, img in zip(axes.flatten(), images):\n",
    "        ax.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "        \n",
    "        \n",
    "def make_img_transition_x(img, depth, is_dx_pos=True):\n",
    "    y_size, x_size = img.shape\n",
    "    additional_img = gen_cloud(x_size + depth, y_size)   \n",
    "    transition_kernel = spatial_smooth_filter(x_size, y_size, depth)     \n",
    "    \n",
    "    new_img = np.copy(img)\n",
    "    if is_dx_pos:\n",
    "        new_img[:, -depth:x_size] = img[:, -depth:x_size] * transition_kernel + \\\n",
    "                                additional_img[:, 0:depth] * (1 - transition_kernel)\n",
    "        return new_img, additional_img[:, depth:]    \n",
    "    else:\n",
    "        transition_kernel = np.fliplr(transition_kernel)\n",
    "        new_img[:, 0:depth] = img[:, 0:depth] * transition_kernel + \\\n",
    "                          additional_img[:, -depth:] * (1 - transition_kernel)  \n",
    "        return new_img, additional_img[:, 0:-depth]    \n",
    "\n",
    "\n",
    "def make_img_transition_y(img, depth, is_dy_pos=True):\n",
    "    y_size, x_size = img.shape\n",
    "    additional_img = gen_cloud(x_size, y_size + depth)   \n",
    "    transition_kernel = spatial_smooth_filter(x_size, y_size, depth, horiz=False)\n",
    "        \n",
    "    new_img = np.copy(img)\n",
    "    if is_dy_pos:\n",
    "        new_img[-depth:x_size, :] = img[-depth:x_size, :] * transition_kernel + \\\n",
    "                                additional_img[0:depth, :] * (1 - transition_kernel)\n",
    "        return new_img, additional_img[depth:, :]    \n",
    "    else:\n",
    "        transition_kernel = np.flipud(transition_kernel)\n",
    "        new_img[0:depth, :] = img[0:depth, :] * transition_kernel + \\\n",
    "                          additional_img[-depth:, :] * (1 - transition_kernel)  \n",
    "        return new_img, additional_img[0:-depth:1, :]    \n",
    "\n",
    "    \n",
    "def freq_2d(x_freq, y_freq):\n",
    "    x, y = np.meshgrid(x_freq, y_freq)\n",
    "    f = np.hypot(x, y)\n",
    "    return f\n",
    "\n",
    "\n",
    "def lin_regression(x, y):\n",
    "    # y - original img\n",
    "    # x - restored img\n",
    "    num = np.mean(x * y) - np.mean(x) * np.mean(y)\n",
    "    denum = np.mean(x ** 2) - np.mean(x) ** 2\n",
    "    a = num / denum\n",
    "    b = np.mean(y) - a * np.mean(x)\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def lin_phase(start, end, size):\n",
    "    pos_freq = np.linspace(start, end, size // 2)\n",
    "    neg_freq = -pos_freq[::-1]\n",
    "    return np.append(neg_freq, pos_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d496154c",
   "metadata": {},
   "source": [
    "### Cumulus test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f05274",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(input_dir + '2.jpg').convert('L')\n",
    "img -= np.mean(img)\n",
    "img_fr = find_ft(img)\n",
    "\n",
    "x_size, y_size = img_fr.shape\n",
    "xx = freq_numbers_1d(x_size)\n",
    "yy = freq_numbers_1d(y_size)\n",
    "\n",
    "magn = np.abs(img_fr)\n",
    "magn = normalize(magn)\n",
    "phase = np.angle(img_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01efdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax1.imshow(img, cmap='gray')\n",
    "\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax2.imshow(np.log(magn), cmap='gray')\n",
    "\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax3.imshow(phase, cmap='gray')\n",
    "\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "ax4.imshow(find_ift(magn * np.exp(1j * phase)).real, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5472c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_fr = find_ft(phase)\n",
    "phase_magn = np.abs(phase_fr)\n",
    "phase_angle = np.angle(phase_fr)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.imshow(phase_magn, cmap='gray')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.imshow(phase_angle, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6237bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_fr = np.sqrt(normalize(phase_magn)) * np.exp(1j * phase_angle)\n",
    "ph = find_ift(ph_fr).real\n",
    "\n",
    "plt.imshow(ph, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e184ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Surface(x=xx, y=yy, z=np.log10(magn)))\n",
    "\n",
    "fig.update_layout(\n",
    "    scene = dict(\n",
    "    zaxis = dict(range=[-5, 0],),\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# fig.add_trace(go.Surface(x=list(range(20)), y=list(range(20)), z=phase[x_size // 2 - 10: x_size // 2 + 10, y_size // 2 - 10: y_size // 2 + 10]))\n",
    "fig.add_trace(go.Surface(x=xx, y=yy, z=phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20149fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase along x axis\n",
    "# plt.plot(phase[x_size // 2 + 2, y_size // 2:])\n",
    "\n",
    "# Phase along y axis\n",
    "plt.plot(phase[x_size // 2:, y_size // 2 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722bbe18",
   "metadata": {},
   "source": [
    "### Generating pseudo random phase trying to mimic same phase distribution along each axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a474a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_phase_y = np.zeros((x_size, y_size))\n",
    "\n",
    "for i in range(x_size):\n",
    "    new_phase_y[i, :] = surrogates(phase[i, :], 1)\n",
    "    \n",
    "    \n",
    "new_phase_x = np.zeros((x_size, y_size))\n",
    "\n",
    "for i in range(x_size):\n",
    "    new_phase_x[:, i] = surrogates(phase[:, i], 1)\n",
    "\n",
    "new_phase_sur = new_phase_x + new_phase_y\n",
    "plt.imshow(new_phase_sur, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caeeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring image using original magnitude and new phase \n",
    "\n",
    "restored_img_fr = magn * np.exp(1j * new_phase_sur)\n",
    "restored_img = find_ift(restored_img_fr).real\n",
    "\n",
    "plt.imshow(restored_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c188b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring image using 1/f kernel for magnitude and new phase \n",
    "# Results are equal to regular FFT syntesis\n",
    "\n",
    "kernel = freq_filter_2d(xx, yy)\n",
    "restored_img_fr = kernel * np.exp(1j * new_phase_sur)\n",
    "restored_img = find_ift(restored_img_fr).real\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax1.imshow(np.log(kernel), cmap='gray')\n",
    "\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax2.imshow(restored_img, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
